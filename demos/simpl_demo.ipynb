{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMPL demo \n",
    "\n",
    "<img src=\"../simpl.gif\" width=850>\n",
    "\n",
    "This demo loads an artificial dataset (the grid cell dataset of figure 3) and train SIMPl to recover the underlying latent space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data\n",
    "SIMPL API requires users to provide spikes, an initial latent variable, and time stamps. \n",
    "Optionally, if you have them, you can also provide the ground truth latent variables such as the _true_ latent variables and the _true_ spikes, but onlyif you have them. Here we will assume you dont s oyuo can \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np \n",
    "import xarray as xr\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SIMPL\n",
    "from simpl.utils import load_datafile, prepare_data\n",
    "from simpl.environment import Environment\n",
    "from simpl.simpl import SIMPL\n",
    "\n",
    "# A seperate package, KalMax, handles backend kalman filtering and KDE estimation\n",
    "import kalmax "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some premade artificial data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_datafile('gridcelldata.npz')\n",
    "\n",
    "print('Required data:')\n",
    "Y = data['Y']; print(f'   {\"Y, spikes:\": <30}{Y.shape}')\n",
    "Xb = data['Xb']; print(f'   {\"Xb, latent initialisation:\": <30}{Xb.shape}')\n",
    "time = data['time']; print(f'   {\"time, time stamps:\": <30}{time.shape}')\n",
    "\n",
    "# optionally, if you have the ground truth trajcetory and tuning curves you can use these too \n",
    "print('\\nOptional ground truth data and other coordinates. You DONT need to have these:')\n",
    "Xt = data['Xt']; print(f'   {\"Xt, ground truth:\": <30}{Xt.shape}')\n",
    "dims = data['dim']; print(f'   {\"dim, dimension names:\": <30}{dims.shape}')\n",
    "neuron = data['neuron']; print(f'   {\"neuron, neuron IDs:\": <30}{neuron.shape}')\n",
    "Ft = data['Ft']; print(f'   {\"Ft, tuning curves:\": <30}{Ft.shape}')\n",
    "xbins = data['x']; print(f'      {\"xbins:\": <27}{xbins.shape}')\n",
    "ybins = data['y']; print(f'      {\"ybins:\": <27}{ybins.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIMPL requires these to be converted to xarrays and compiled as an xarray.Dataset. We provide a helper function for this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(\n",
    "    Y=Y, \n",
    "    Xb=Xb,\n",
    "    time=time, \n",
    "\n",
    "    # Optional arguments (just comment these out if you don't have ground truth) \n",
    "    dims = dims,\n",
    "    neurons=neuron,\n",
    "    Xt=Xt,\n",
    "    Ft=Ft,\n",
    "    Ft_coords_dict={'x': xbins, 'y': ybins}\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the environment\n",
    "\n",
    "SIMPL requires you to make an `Environment` object. This contains a number of attributes but, in essence, creates a discretised hyperrectangular environment inside which the latent variables are defined.\n",
    "\n",
    "`DX`, the environment gridscale, determines the bin size. Tuning curves are estimated over all bins in the environment so computational cost should scale like ($\\frac{1}{N_{\\textrm{bins}}}^{D}).\n",
    "In practice the algorithm is not as sensitive to this parameter as one might expect and position decoding is still fully-continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 0.0 # any extra room to add to the edges of the environment around the data\n",
    "DX = 0.02\n",
    "env = Environment(\n",
    "    X = data.Xb.values, # data is only needed here to calculate the required size and number of dimensions\n",
    "    pad = PAD, # padding (in meters) for the latent space outside the data bounds \n",
    "    bin_size = DX, # bin size in meters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the SIMPL model \n",
    "\n",
    "SIMPL takes in `data` and `env` as arguments and optionally a small number of other parameters listed here so you can see what they are and play around with them if you wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = kalmax.kernels.gaussian_kernel\n",
    "kernel_bandwidth = 0.02                 # bandwidth of the KDE kernel in meters for fitting the tuning curves\n",
    "observation_noise_std = 0.04            # additional kalman observation noise (ontop of likelihood gaussian width)\n",
    "speed_prior = 0.4                       # prior on the speed of the animal in meters per second\n",
    "test_frac = 0.1                         # fraction of spikes to withold as test set\n",
    "speckle_block_size_seconds = 1          # block size for speckle noise in seconds\n",
    "manifold_align_against = 'behaviour'    # whether or not to linearly align the latent against behaviour on each iteration\n",
    "evaluate_each_epoch = True              # whether or not to do a full evaluation of the model after each epoch (bit slower but not much)\n",
    "save_likelihood_maps = False            # whether or not to save likelihood maps for each timestep (lots of memory, on do this if you really need them) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpl_model = SIMPL(\n",
    "    data = data,\n",
    "    environment = env,\n",
    "    # Optional \n",
    "    kernel = kernel,\n",
    "    kernel_bandwidth = kernel_bandwidth,\n",
    "    observation_noise_std = observation_noise_std,\n",
    "    speed_prior = speed_prior,\n",
    "    test_frac = test_frac,\n",
    "    speckle_block_size_seconds = speckle_block_size_seconds,\n",
    "    manifold_align_against = manifold_align_against,\n",
    "    evaluate_each_epoch = evaluate_each_epoch,\n",
    "    save_likelihood_maps = save_likelihood_maps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the SIMPL model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used ground truth Xt and Ft to calculate some baseline metrics such as the log-likelihood of the spikes under the ground truth tuning curves/trajectory\n",
    "# If there is no ground truth this should throw a warning \n",
    "simpl_model.calculate_baselines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the model for N epochs \n",
    "simpl_model.train_N_epochs(N=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the results \n",
    "\n",
    "All the results are stored in a big xarray.Dataset object. There's a lot of stuff in there and all the coordinates come included so it should be fairly straightforward to use this to generate whatever plots you are interested in\n",
    "\n",
    "`results = simpl_model.results`\n",
    "\n",
    "Note epochs -1 and -2 (if present) represent the \"baselines\". They are two subtely different versions of the ground truth (see the source code for details)\n",
    "\n",
    "If you are unsure what a quantity represents you can always check its meta data stored within the xarray object.\n",
    "\n",
    "The most important results are: \n",
    "\n",
    "- `results.F`: tuning curves across epochs\n",
    "- `results.X`: inferred latent variables across epochs\n",
    "- `results.logPYXF`: log likelihood of the data given the inferred latent variables and tuning curves\n",
    "- `results.Xt`: ground truth latent variables\n",
    "- `results.Ft`: ground truth tuning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = simpl_model.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot latent at epochs 0, 1, 2,... alongside the true latent (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeslice = slice(0, 120)\n",
    "t = results.time.sel(time=timeslice).values\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 2))\n",
    "for epoch in range(0, results.epoch.values[-1]+1):\n",
    "    X = results.X.sel(epoch=epoch,time=timeslice).values\n",
    "    ax.plot(t, X[:,0], color=matplotlib.cm.plasma(epoch/results.epoch.values[-1]), alpha=0.5, label = (f'Epoch {epoch}' if epoch in [0, results.epoch.values[-1]] else None))\n",
    "\n",
    "if 'Xt' in results.keys():\n",
    "    XT = results.Xt.sel(time=timeslice).values\n",
    "    ax.plot(t,  XT[:,0], 'k', ls='--',label='Ground truth')\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('x-position (m)')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the receptive field of one of the neurons at epoch 0, 1, 2,... alongside the true receptive field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, results.epoch.values[-1]+2, figsize=(10, 2), sharex=True, sharey=True)\n",
    "for epoch in range(0, results.epoch.values[-1]+1):\n",
    "    F = results.F.sel(epoch=epoch, neuron=10)\n",
    "    ax[epoch].imshow(F, cmap='inferno')\n",
    "    ax[epoch].set_title(f'{epoch}')\n",
    "    # edge_map = results.place_field_outlines.sel(epoch=epoch, neuron=10).values[::-1].astype(float)\n",
    "    # edge = ax[epoch].imshow(edge_map,extent=env.extent, cmap='Greys_r', alpha=edge_map,zorder=10)\n",
    "    \n",
    "if 'Ft' in results.keys():\n",
    "    FT = results.Ft.sel(neuron=10)\n",
    "    ax[-1].imshow(FT.T[::-1,::-1], cmap='inferno')\n",
    "    ax[-1].set_title('Ground truth')\n",
    "else:\n",
    "    ax[-1].set_title('No ground truth :(')\n",
    "    ax[-1].axis('off')\n",
    "\n",
    "# TODO fix why ground truth is reflected "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the log-likelihood of spikes at each epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "for i in range(0, results.epoch.values[-1]+1):\n",
    "    ax.scatter(results.epoch[i], results.logPYXF.sel(epoch=i), label=f'Epoch {i}', color=matplotlib.cm.plasma(i/results.epoch.values[-1]))\n",
    "    ax.scatter(results.epoch[i], results.logPYXF_test.sel(epoch=i), label=f'Epoch {i}', color='w', edgecolors=matplotlib.cm.plasma(i/results.epoch.values[-1]), linewidth=2)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Log likelihood')\n",
    "if -1 in results.epoch.values:\n",
    "    ax.axhline(results.logPYXF.sel(epoch=-1), color='k', ls='--', label='Ground truth')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
